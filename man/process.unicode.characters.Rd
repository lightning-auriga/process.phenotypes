% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/string_vector_cleanup.R
\name{process.unicode.characters}
\alias{process.unicode.characters}
\title{Convert sporadic Unicode-only characters into lesser equivalents}
\usage{
process.unicode.characters(phenotype.data)
}
\arguments{
\item{phenotype.data}{Data frame of input phenotype data as character vectors.}
}
\value{
Data frame, containing input data with recognized Unicode characters converted
into more manageable equivalents.
}
\description{
Sporadic Unicode characters can be inserted into datasets by
upstream text editors. This function attempts to take them right
back out again. Replacements are defined in a text linker function
under system.file("unicode_pattern_replacements.tsv", package = "process.phenotypes").
}
\details{
Via unknown reasons, something particularly strange can happen with
Excel's "=#ERROR!" code, as in one instance it can be converted
into, of all things, an emoji. The particular instance of this that we've
encountered should be automatically handled, but every time we process
a new dataset we find new, creative instances of things that were
supposed to be other things.

The text linker file does a much better job of transparently exposing
the pattern conversions than previous implementations. However, there
are supposedly, according to relevant documentation, certain issues
that may be introduced when such pattern linking is attempted on Windows.
We have yet to actually observe this phenomenon ourselves, but it
is nevertheless theoretically possible. If anyone reading this ever
observes any such issue, please post an issue about it to the repo.
}
\examples{
phenotype.data <- data.frame(subjid = c("A", "B", "C", "\u2070"))
result <- process.phenotypes:::process.unicode.characters(phenotype.data)
}
